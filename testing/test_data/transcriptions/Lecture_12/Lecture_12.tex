\documentclass[11pt]{article}
\usepackage{aahomework}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{epstopdf}
\usepackage{float}
\usepackage{xcolor}
\usepackage{parskip}
%\tikzstyle{blk}=[circle,inner sep=0pt,minimum size =4pt,draw,fill=black,line width=0.8pt]
%\tikzstyle{blanknode}=[circle,inner sep=3pt,minimum size =8pt,draw,line width=0.8pt]
%
%\geometry{letterpaper, textwidth=17cm, textheight=22cm}

%\usetikzlibrary{arrows}
%\usetikzlibrary{plotmarks}

\newcommand{\ques}{\paragraph{Question:}}
\newcommand{\keyphrase}{\textbf}
\newcommand{\boxit}[2]{\textcolor{#1}{\boxed{\textcolor{black}{#2}}}}
\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\vek}[1]{\vec{#1}}
\newcommand{\note}{\textsc{Note:} }
\newcommand{\rank}{\text{rank}}

\title{Lecture 12}
\author{A. Agarwal}
\date{August 6, 2012}


\begin{document}
%\maketitle

\section*{Recall}

\begin{enumerate}
\item{
Vector space: $(V, +, \cdot)$ with ten axioms
}
\item{
Subspace: a subset of a vector space that is a vector space on its own.
}
\end{enumerate}

\vspace{1cm}

Recall that to ensure that a subset $S \subseteq V$ is a subspace of $V$, we must have that
\begin{enumerate}
\item{
$S$ is nonempty.
}
\item{
$S$ is closed under addition.
}
\item{
$S$ is closed under scalar multiplication.
}
\end{enumerate}
These last two items can be understood as $S$ being closed under \emph{linear combinations}. That is, $S$ is a subspace if for every $\vek{u}, \vek{v} \in S$ and $c_1, c_2 \in \bbR$ (scalars), then $c_1 \vek{u} + c_2 \vek{v} \in S$.

\section*{Defining Operations}
The usual definitions for addition and multiplication are not the only ones possible. Let us look at some examples. Consider the set
\begin{align*}
V = \left\{ \begin{pmatrix}x \\ y\end{pmatrix} : x,y \in \bbR \right\}
\end{align*}
with addition and scalar multiplication defined as
\begin{align*}
\begin{pmatrix}x \\ y\end{pmatrix} + \begin{pmatrix}a \\ b\end{pmatrix} &= \begin{pmatrix}x + a \\ y + b\end{pmatrix}
\\
c \begin{pmatrix}x \\ y\end{pmatrix} &= \begin{pmatrix}x \\ cy\end{pmatrix}
\end{align*}
\ques Is $V$ with these operations a vector space or not?

To answer this, we must check each of the requirements of a vector space.

\paragraph{Additive closure} Since this is the usual definition of addition, it is closed under addition.

\paragraph{Scalar multiplication} To check whether the scalar multiplication defined here satisfies the axioms, let $\begin{pmatrix}x \\ y \end{pmatrix} \in V$ and $c \in \bbR$. Then $c \begin{pmatrix}x \\ y\end{pmatrix} = \begin{pmatrix}x \\ cy\end{pmatrix}$ and since $x, cy \in \bbR$, then $\begin{pmatrix}x \\ cy\end{pmatrix} \in V$, hence $V$ is closed under scalar multiplication.

\paragraph{Zero vector}
\begin{claim}
$\begin{pmatrix}0 \\ 0\end{pmatrix} \in V$ is the zero vector.
\end{claim}
\begin{proof}
\begin{align*}
\begin{pmatrix}x \\ y\end{pmatrix} + \begin{pmatrix}0 \\ 0\end{pmatrix} = \begin{pmatrix}x + 0 \\ y + 0\end{pmatrix} = \begin{pmatrix}x \\ y\end{pmatrix}
\end{align*}
\end{proof}

\vspace{1cm}
Since addition here is the same as the usual addition, if there is a problem with these definitions that prevents the space from being a vector space, it must have something to do with the multiplication operation.

\paragraph{Distributivity} A vector space must satisfy distributivity: $(c + d) \vek{u} = c \vek{u} + d \vek{u}$

To check whether this holds in this space, let $\vek{u} = \begin{pmatrix}x \\ y\end{pmatrix}$ and $c,d \in \bbR$. Then
\begin{align*}
(c + d) \vek{u} = (c+d) \begin{pmatrix}x \\ y\end{pmatrix} = \begin{pmatrix}x \\ (c+d)y \end{pmatrix}
\end{align*}
\begin{align*}
c \vek{u} + d \vek{u} = c \begin{pmatrix}x \\ y\end{pmatrix} + d \begin{pmatrix}x \\ y\end{pmatrix}
= \begin{pmatrix}x \\ cy\end{pmatrix} + \begin{pmatrix}x \\ dy\end{pmatrix}
= \begin{pmatrix}2x \\ (c+d)y\end{pmatrix}
\end{align*}
Since $x$ will not always equal $2x$, the result fails and we can conclude that $V$ with these operations is \emph{not} a vector space.

Though this set with these operations is not a vector space, can it be that perhaps other operations would maintain the vector space structure?

\vspace{1cm}

Consider the set
\begin{align*}
V = \left\{ x | x > 0 \right\} = \bbR^+
\end{align*}
For clarity, define addition $\oplus$ and scalar multiplication $\odot$ as follows:
\begin{align*}
x \oplus y &= xy
\\
c \odot x &= x^c
\end{align*}
where $x,y \in \bbR^+$ (the vector space) and $c \in \bbR$ (a scalar).

\ques Is $(\bbR^+, \oplus, \odot)$ a vector space?

\begin{enumerate}
\item{
Closure under $\oplus$

Let $x,y \in V$ (so $x,y > 0$). Then
\begin{align*}
x \oplus y &= xy > 0
\end{align*}
Therefore $x \oplus y \in V$.
}
\item{
Closure under $\odot$

Let $c \in \bbR$ and $x \in V$. Then since $x > 0$,
\begin{align*}
c \odot x = x^c > 0
\end{align*}
Therefore $c \odot x \in V$.
}
\item{
Zero element

Suppose some element $z \in V$ is the zero element. Then for any $x \in V$,
\begin{align*}
x \odot z &= x
\\
xz &= x
\\
x(z-1) &= 0
\end{align*}
Thus $z = 1$ would have to be the zero element. Since $1 > 0$, thus $1 \in V$ and so the zero element is in fact $z=1$.
}
\item{
Inverse of an element

Let $x \in V$. Then we want some $t \in V$ such that
\begin{align*}
x \oplus t &= t \oplus x = z
\end{align*}
where $z$ is the zero vector. Remember that we have just found that $z=1$ is the zero element, rather than the usual $z=0$. Carrying out these operations, we have that
\begin{align*}
xt &= 1
\\
t &= \frac{1}{x}
\end{align*}
Since $x \in V$, thus $x > 0$, so $\frac{1}{x} > 0$. Thus $t = \frac{1}{x} \in V$. That is, for each $x \in V$, the element $\frac{1}{x}$ is its additive inverse.
}
\item{
To check the axiom:
\begin{align*}
(c + d) \odot \vek{u} = c \odot \vek{u} \oplus d \odot \vek{u}
\end{align*}
where $c,d \in \bbR$ and $\vek{u} = x \in V$ (so $x > 0$).

Starting with the left-hand side:
\begin{align*}
(c+d) \odot \vek{u} &= (c+d) \odot x
\\
&= x^{c+d}
\\
&= (x^c) \cdot (x^d)
\\
&= (c \odot x) \cdot (d \odot x)
\\
&= (c \odot x) \oplus (d \odot x)
\\
&= c \odot \vek{u} \oplus d \odot \vek{u}
\end{align*}
we arrive at the right-hand side, indicating the axiom holds.
}
\end{enumerate}
It turns out that this set does in fact satisfy all of the vector space axioms. With such strange operations, it brings to light that our standard vector spaces are by no means the only ones.
\ques Is $(V,+,\cdot) \iso (V, \oplus, \odot)$?

\section*{Subspaces of $\bbR^2$}
You may recall that all the subspaces of $\bbR^2$ are:
\begin{enumerate}
\item{
$\bbR^2$
}
\item{
$\left\{ \begin{pmatrix}0 \\ 0\end{pmatrix} \right\}$
}
\item{
All straight lines through the origin.
}
\end{enumerate}
To see why this is the case, let us outline the proof:
\begin{proof}
Let $S$ be a subspace of $\bbR^2$. Note that if $S = \left\{ \begin{pmatrix}0 \\ 0\end{pmatrix}\right\}$, then $S$ is indeed a subspace. Otherwise, let $\vek{u} \in S$ such that $\vek{u} \neq \vek{0}$. Then since $S$ is a subspace, thus $c \vek{u} \in S$ for all $c \in \bbR$. Thus it contains the straight line along $\vek{u}$ that passes through the origin.

If $S$ has no other vector, then $S$ is simply that straight line. Otherwise, assume there exists some non-zero $\vek{v} \in S$ that is linearly independent of $\vek{u}$.

Note then that $\text{span} \left\{ \vek{u}, \vek{v} \right\} = \bbR^2$ (Why?)
\end{proof}

\vspace{1cm}

The above proof is not quite complete. The question is why we can gaurantee that $\text{span} \left\{ \vek{u}, \vek{v} \right\} = \bbR^2$?

What this amounts to is whether for any vector $\vek{w} \in \bbR^2$ there exist some scalars $c_1, c_2 \in \bbR$ such that
\begin{align*}
c_1 \vek{u} + c_2 \vek{v} &= \vek{w}
\end{align*}
This is a linear system with corresponding augmented matrix looking like:
\begin{align*}
\begin{bmatrix}
\uparrow & \uparrow & \uparrow
\\
\vek{u} & \vek{v} & \vek{w}
\\
\downarrow & \downarrow & \downarrow
\end{bmatrix}
\end{align*}
Since $\vek{u} \neq c \vek{v}$, that is, they are linearly independent, then the coefficient matrix portion of this augmented matrix is invertible. Thus its columns will span $\bbR^2$.

\end{document}
