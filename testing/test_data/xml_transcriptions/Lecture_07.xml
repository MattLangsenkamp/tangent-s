<?xml version="1.0" encoding="UTF-8"?>
<math xmlns="http://www.w3.org/1998/Math/MathML" alttext="\documentclass[11pt]{article}\usepackage{aahomework}\usepackage{mathtools}%&#10;\usepackage{subcaption}\usepackage{epstopdf}\usepackage{float}\usepackage{%&#10;xcolor}\usepackage{parskip}\tikzstyle{blk}=[circle,innersep=0pt,minimumsize=4%&#10;pt,draw,fill=black,linewidth=0.8pt]\tikzstyle{blanknode}=[circle,innersep=3pt,%&#10;minimumsize=8pt,draw,linewidth=0.8pt]\par&#10;\geometry{letterpaper,textwidth=17cm%&#10;,textheight=22cm}\par&#10;\usetikzlibrary{arrows}\usetikzlibrary{plotmarks}\par&#10;%&#10;\par&#10;\par&#10;\begin{document}&#10;\par&#10;\@@section{section}{Sx1}{}{}{}{Recall}&#10;\par&#10;\begin{enumerate}&#10;\enumerate@item{&#10;A set of vectors $\left\{\vec{v}_{1},\vec{v}_{2},\dots,\vec{v}_{k}\right\}$ in%&#10; $\bbR^{n}$ is \emph{linearly independent} if the following \emph{homogenous} %&#10;equation has only the zero (trivial) solution:&#10;\@@amsalign$\displaystyle c_{1}\vec{v}_{1}+c_{2}\vec{v}_{2}+\dots+c_{k}\vec{v}%&#10;_{k}$&amp;$\displaystyle=0$&#10;\par&#10; Note that \eqref{eq:eq1} always has a solution, namely $c_{1}=c_{2}=%&#10;\dots=c_{k}=0$. Our interest is whether this is the \emph{only solution}, or %&#10;if there are others.&#10;\par&#10; It is a common mistake when we first learn this to think that something %&#10;like ``since we can form a linear combination with $c_{1},c_{2},\dots,c_{k}=0$%&#10;, thus the set is dependent.''. This is not the case; it must be a solution %&#10;with at least one coefficient non-zero.&#10;}&#10;\enumerate@item{&#10;If the number of vectors in $S$ is greater than the dimension of the space, %&#10;then $S$ is dependent.&#10;\par&#10; Suppose $\left\{\vec{v}_{1},\vec{v}_{2},\dots,\vec{v}_{k}\right\}$ is a %&#10;\emph{dependent set}. Then there is at least one $c_{i}\neq 0$. Without loss %&#10;of generality, say $c_{1}\neq 0$. Then&#10;\@@amsalign$\displaystyle c_{1}\vec{v}_{1}$&amp;$\displaystyle=-c_{2}\vec{v}_{2}-%&#10;\dots-c_{k}\vec{v}_{k}$\\&#10;$\displaystyle\vec{v}_{1}$&amp;$\displaystyle=-\frac{c_{2}}{c_{1}}\vec{v}_{2}-%&#10;\dots-\frac{c_{k}}{c_{1}}\vec{v}_{k}$&#10;The righthand side of this equation should remind us of the span. In this case%&#10;, of $\text{Span}\left\{\vec{v}_{2},\dots,\vec{v}_{k}\right\}$. That is, $\vec%&#10;{v}_{1}$ lies in the span of the other $\vec{v}_{i}$'s.&#10;}&#10;\end{enumerate}&#10;\par&#10;\@@section{section}{Sx2}{}{}{}{Linear Independence}&#10;\par&#10;\@@section{paragraph}{Sx2.SS0.SSS0.Px1}{}{}{}{Question:}Consider the set %&#10;of vectors $S=\left\{\vec{0},\vec{v}_{2},\dots,\vec{v}_{k}\right\}$. Is $S$ %&#10;independent or dependent? To answer this, we must ask whether the following %&#10;homogeneous equation has a non-zero solution:&#10;\@@amsalign$\displaystyle c_{1}\vec{0}+c_{2}\vec{v}_{2}+\dots+c_{k}\vec{v}_{k}%&#10;$&amp;$\displaystyle=\vec{0}$&#10;Consider for instance the solution $c_{1}=3$, $c_{2},c_{3},\dots,c_{k}=0$. %&#10;This is a non-zero or non-trivial solution, hence $S$ must be dependent.&#10;\par&#10;\@@section{paragraph}{Sx2.SS0.SSS0.Px2}{}{}{}{Question:}Let $S=\left\{%&#10;\vec{v}_{1},\vec{v}_{2},\vec{v}_{3}\right\}$.&#10;Suppose none of the vectors in $S$ are zero vectors, and each is perpendicular%&#10; to one another. That is,&#10;\@@amsalign$\displaystyle\vec{v}_{i}\neq\vec{0}$&amp;$$&amp;$\displaystyle\vec{v}_{i}%&#10;\perp\vec{v}_{j}\quad\text{for all $i\neq j$}$&#10;Is $S$ independent or dependent? Before we answer this question, we should %&#10;observe some noteworthy aspects of this question and how it is posed. If we %&#10;can find some useful relationships between orthogonality and linear dependence%&#10;, we will perhaps uncover illuminating geometric relationships.&#10;\par&#10; To answer the question at hand, we can start with the equation we %&#10;already know: the linear combination of vectors that equals the zero vector:&#10;\@@amsalign$\displaystyle c_{1}\vec{v}_{1}+c_{2}\vec{v}_{2}+c_{3}\vec{v}_{3}$&amp;%&#10;$\displaystyle=\vec{0}$&#10;it is initially unclear how the orthogonality will come into play, but %&#10;consider taking the dot product of both sides of the equation with $\vec{v}_{1%&#10;}$:&#10;\@@amsalign$\displaystyle\left(c_{1}\vec{v}_{1}+c_{2}\vec{v}_{2}+c_{3}\vec{v}_%&#10;{3}\right)\cdot\vec{v}_{1}$&amp;$\displaystyle=\vec{0}\cdot\vec{v}_{1}$\\&#10;$\displaystyle c_{1}\left(\vec{v}_{1}\cdot\vec{v}_{1}\right)+c_{2}\left(\vec{v%&#10;}_{2}\cdot\vec{v}_{1}\right)+c_{3}\left(\vec{v}_{3}\cdot\vec{v}_{1}\right)$&amp;$%&#10;\displaystyle=0$&amp;$\displaystyle\text{Distributive property of dot product}$\\&#10;$\displaystyle c_{1}||\vec{v}_{1}||^{2}+c_{2}(0)+c_{3}(0)$&amp;$\displaystyle=0$&amp;$%&#10;\displaystyle\text{The vectors are orthogonal to each other}$\\&#10;$\displaystyle c_{1}||\vec{v}_{1}||^{2}$&amp;$\displaystyle=0$&#10;Since $\vec{v}_{1}\neq\vec{0}$, we know that $||\vec{v}_{1}||^{2}\neq 0$. Thus%&#10; from the above, $c_{1}=0$.&#10;\par&#10; Likewise, we find that $c_{2}=c_{3}=0$ by taking the dot product with $%&#10;\vec{v}_{2}$ and $\vec{v}_{3}$.&#10;\par&#10; Therefore, the only solution is the zero solution. Thus $S$ must be %&#10;independent.&#10;\par&#10;{Note:} In an $n$-dimensional space we cannot have more than $n$ (non-%&#10;zero) orthogonal vectors.&#10;\par&#10;\@@section{section}{Sx3}{}{}{}{Matrices}&#10;We have already seen some examples of matrices as means of storing systems of %&#10;linear equations. They are simply arrays of numbers laid out in a way in which%&#10; each entry has a convenient address.&#10;{\Large\@@amsalign$\displaystyle\mathbf{A}=\begin{bmatrix}a_{1,1}&amp;a_{1,2}&amp;a_{1%&#10;,3}\\&#10;a_{2,1}&amp;a_{2,2}&amp;a_{2,3}\end{bmatrix}\qquad\mathbf{A}_{2\times 3}$&#10;}&#10;The $i-j^{\text{th}}$ entry is the entry found in row $i$ and column $j$. We %&#10;always give the address of the entry row first and column second&#10;\par&#10; Every matrix is described by its entries, and we sometimes write it like%&#10; below:&#10;\@@amsalign$\displaystyle\mathbf{A}=\Big(a_{ij}\Big)\qquad a_{ij}\in\bbR,\bbC$&#10;For our purposes, the entries will almost always be from $\bbR$ and $\bbC$, %&#10;but keep in mind that the entries could be any object.&#10;\par&#10; It is also important to note the size of a matrix, and we often do this %&#10;by saying that $\mathbf{A}$ is an $n\times m$ matrix, or writing $\mathbf{A}_{%&#10;n\times m}$.&#10;\@@section{subsection}{Sx3.SSx1}{}{}{}{Algebra of Matrices}&#10;Suppose $\mathbf{A}_{m\times n}$ and $\mathbf{B}_{m\times n}$ are matrices of %&#10;the same size. We define several operations on matrices as follows:&#10;\begin{table}[H]&#10;\centering\begin{tabular}[]{c | &gt;{$}r&lt;{$}@{$\,=\,$} &gt;{$}l&lt;{$} &gt;{$}c&lt;{$}}%&#10;Operation&amp;\omit\span\omit\text{Definition by Entry}&amp;\text{Resultant Size}\\&#10;\hline\hline Matrix addition&amp;\mathbf{A} + \mathbf{B}$\,=\,$&amp;\Big( a_{ij} + b_{%&#10;ij} \Big)&amp;m \times n\\&#10;Matrix subtraction&amp;\mathbf{A} - \mathbf{B}$\,=\,$&amp;\Big( a_{ij} - b_{ij} \Big)&amp;%&#10;m \times n\\&#10;Scalar multiplication&amp;c \mathbf{A}$\,=\,$&amp;\Big( c \, a_{ij} \Big) \qquad\text{%&#10;$c$ is a scalar}&amp;m \times n\end{tabular}&#10;\@add@centering\end{table}&#10;\par&#10;\@@section{paragraph}{Sx3.SSx1.SSS0.Px1}{}{}{}{Example.}&#10;\@@amsalign$\displaystyle\mathbf{A}=\begin{bmatrix}[rrr]1&amp;2&amp;3\\&#10;0&amp;1&amp;-5\end{bmatrix}$&amp;$$&amp;$\displaystyle\mathbf{B}=\begin{bmatrix}[rrr]5&amp;6&amp;-6\\&#10;0&amp;0&amp;3\end{bmatrix}$&amp;$$&amp;$\displaystyle\mathbf{C}=\begin{bmatrix}[rrr]1&amp;2\\&#10;3&amp;0\end{bmatrix}$&#10;Then $\mathbf{A}+5\mathbf{B}$ is given by&#10;\@@amsalign$\displaystyle\mathbf{A}+5\mathbf{B}=\begin{bmatrix}[rrr]1&amp;2&amp;3\\&#10;0&amp;1&amp;-5\end{bmatrix}+\begin{bmatrix}[rrr]25&amp;30&amp;-30\\&#10;0&amp;0&amp;15\end{bmatrix}=\begin{bmatrix}[rrr]26&amp;32&amp;-27\\&#10;0&amp;1&amp;10\end{bmatrix}$&#10;\par&#10; Some may wonder what the result of an addition such as $\mathbf{A}+%&#10;\mathbf{C}$ would be. Since the dimensions of these matrices do not match, %&#10;such an addition is not defined. It is common to wonder whether we could just %&#10;add a column of zeros to the matrix $\mathbf{C}$ in order to make the %&#10;operation defined. The response to this is that of course we could do that, %&#10;but it would completely change the matrix $\mathbf{C}$, so we do not allow %&#10;this type of operation.&#10;\par&#10; These are the simplest types of operations we can define on matrices. %&#10;Two elementary operations remain: multiplication and division. We might also %&#10;wonder about operations such as logarithm and exponentiation. We will get to %&#10;those types of operations later.&#10;\par&#10;\@@section{subsection}{Sx3.SSx2}{}{}{}{Matrix Multiplication}&#10;Matrix multiplication at first seems very strange. If we consider trying to %&#10;define a multiplication on two matrices, we might conclude from seeing %&#10;addition and subtraction that to multiply matrices they should be the same %&#10;size. In fact this is not the case.&#10;\par&#10; Before we discuss the full definition of matrix multiplication, consider%&#10; the dot product:&#10;\@@amsalign$\displaystyle\begin{bmatrix}1&amp;2&amp;3\end{bmatrix}\cdot\begin{bmatrix}%&#10;a\\&#10;b\\&#10;c\end{bmatrix}=a+2b+3c$&#10;If the vectors had an unequal number of components then the dot product would %&#10;not be defined. If we consider the scalar $a+2b+3c$ to be the sole entry in a %&#10;matrix of size $1\times 1$, then this tells us one possible set of sizes for %&#10;which matrix multiplication is defined:&#10;\@@amsalign$\displaystyle\underbrace{\begin{bmatrix}1&amp;2&amp;3\end{bmatrix}}_{1%&#10;\times 3}\underbrace{\begin{bmatrix}a\\&#10;b\\&#10;c\end{bmatrix}}_{3\times 1}=\underbrace{\begin{bmatrix}a+2b+3c\end{bmatrix}}_{%&#10;1\times 1}$&#10;The dimensions of matrices that can be multiplied can be summarized as&#10;{\Large\@@amsalign$\displaystyle\mathbf{A}_{m\times n}\,\mathbf{B}_{n\times p}%&#10;=\mathbf{C}_{m\times p}$&#10;}&#10;\par&#10;\@@section{paragraph}{Sx3.SSx2.SSS0.Px1}{}{}{}{Example.}&#10;\@@amsalign$\displaystyle\mathbf{A}_{2\times 3}=\begin{bmatrix}1&amp;2&amp;3\\&#10;-1&amp;4&amp;0\end{bmatrix}$&amp;$$&amp;$\displaystyle\mathbf{B}_{3\times 1}=\begin{bmatrix}p%&#10;\\&#10;q\\&#10;r\end{bmatrix}$&#10;Consider the product&#10;\@@amsalign$\displaystyle\mathbf{A}\mathbf{B}$&amp;$\displaystyle=\begin{bmatrix}1%&#10;&amp;2&amp;3\\&#10;-1&amp;4&amp;0\end{bmatrix}\begin{bmatrix}p\\&#10;q\\&#10;r\end{bmatrix}$&#10;We can evaluate this by ignoring one row at a time of $\mathbf{A}$:&#10;\@@amsalign$\displaystyle\left.\begin{aligned}\displaystyle\mathbf{A}\mathbf{B%&#10;}&amp;\displaystyle=\begin{bmatrix}1&amp;2&amp;3\\&#10;\end{bmatrix}\begin{bmatrix}p\\&#10;q\\&#10;r\end{bmatrix}=\begin{bmatrix}p+2q+3r\\&#10;\end{bmatrix}\\&#10;\displaystyle\mathbf{A}\mathbf{B}&amp;\displaystyle=\begin{bmatrix}\\&#10;-1&amp;4&amp;0\end{bmatrix}\begin{bmatrix}p\\&#10;q\\&#10;r\end{bmatrix}=\begin{bmatrix}\\&#10;-p+4q+0r\end{bmatrix}\end{aligned}\right\}$&amp;$$&amp;$\displaystyle\longrightarrow$&amp;%&#10;$$&amp;$\displaystyle\begin{aligned}\displaystyle\mathbf{A}\mathbf{B}&amp;%&#10;\displaystyle=\begin{bmatrix}1&amp;2&amp;3\\&#10;-1&amp;4&amp;0\end{bmatrix}\begin{bmatrix}p\\&#10;q\\&#10;r\end{bmatrix}\\&#10;&amp;\displaystyle=\begin{bmatrix}p+2q+3r\\&#10;-p+4q+0r\end{bmatrix}_{2\times 1}\end{aligned}$&#10;\par&#10; It may be startling to observe the outcome of trying to multiply $%&#10;\mathbf{B}$ by $\mathbf{A}$:&#10;\@@amsalign$\displaystyle\mathbf{B}_{3\times 1}\mathbf{A}_{2\times 3}$&amp;$%&#10;\displaystyle=\text{Not defined}$&#10;Because the dimensions of the two matrices do not correctly line up in this %&#10;order, they cannot be multiplied in this way. The technical term for this is %&#10;that, in general, matrix multiplication is {non-commutative}. That is, $%&#10;\mathbf{A}\mathbf{B}\neq\mathbf{B}\mathbf{A}$. In fact, both need not be %&#10;defined at all, depending on their sizes.&#10;\par&#10;\@@section{subsection}{Sx3.SSx3}{}{}{}{Another Perspective on Matrix %&#10;Multiplication}&#10;Consider again the matrix multiplication from the previous example. We can %&#10;view this multiplication in a number of ways:&#10;\@@amsalign$\displaystyle\mathbf{A}\mathbf{B}$&amp;$\displaystyle=\begin{bmatrix}1%&#10;&amp;2&amp;3\\&#10;-1&amp;4&amp;0\end{bmatrix}\begin{bmatrix}p\\&#10;q\\&#10;r\end{bmatrix}$\\&#10;$$&amp;$\displaystyle=\begin{bmatrix}p+2q+3r\\&#10;-p+4q+0r\end{bmatrix}$&amp;$$&amp;$\displaystyle\Longleftarrow\text{Each row is a %&#10;linear combination of rows of $\mathbf{B}$}$\\&#10;$$&amp;$\displaystyle=p\begin{bmatrix}1\\&#10;-1\end{bmatrix}+q\begin{bmatrix}2\\&#10;4\end{bmatrix}+r\begin{bmatrix}3\\&#10;0\end{bmatrix}$&amp;$$&amp;$\displaystyle\Longleftarrow\text{Linear combination of the%&#10; columns of $\mathbf{A}$}$&#10;The three ways of viewing matrix multiplication are&#10;\begin{enumerate}&#10;\enumerate@item{&#10;\@@amsalign$\displaystyle c_{ij}=\begin{pmatrix}\leftarrow\text{row $i$ of $%&#10;\mathbf{A}$}\rightarrow\end{pmatrix}\begin{pmatrix}\uparrow\\&#10;\text{col. $j$}\\&#10;\text{of $\mathbf{B}$}\\&#10;\downarrow\end{pmatrix}$&#10;}&#10;\enumerate@item{&#10;$i^{\text{th}}$ row of $\mathbf{C}$ is a linear combination of rows of $%&#10;\mathbf{B}$ with coefficients from the $i^{\text{th}}$ row of $\mathbf{A}$.&#10;}&#10;\enumerate@item{&#10;$j^{\text{th}}$ column of $\mathbf{C}$ is a linear combination of columns of $%&#10;\mathbf{A}$ with coefficients from the $j^{\text{th}}$ column of $\mathbf{B}$.&#10;}&#10;\end{enumerate}&#10;\par&#10;\@@section{paragraph}{Sx3.SSx3.SSS0.Px1}{}{}{}{Example.} We will try %&#10;multiplication with each of the three ways of viewing matrix multiplication.&#10;\@@amsalign$\displaystyle\mathbf{A}=\begin{bmatrix}1&amp;2\\&#10;0&amp;1\end{bmatrix}$&amp;$$&amp;$\displaystyle\mathbf{B}=\begin{bmatrix}1&amp;2\\&#10;0&amp;0\\&#10;-1&amp;12\end{bmatrix}$&#10;Note that $\mathbf{A}\mathbf{B}$ is not defined, but $\mathbf{B}\mathbf{A}$ is%&#10; defined. Let $\mathbf{C}=\mathbf{B}\mathbf{A}$, the matrix whose entries we %&#10;will try to find.&#10;\par&#10;\begin{enumerate}&#10;\enumerate@item{&#10;First method:&#10;\par&#10;\@@amsalign$\displaystyle\mathbf{C}=\begin{bmatrix}c_{11}&amp;c_{12}\\&#10;c_{21}&amp;c_{22}\\&#10;c_{31}&amp;c_{32}\end{bmatrix}_{3\times 2}$&#10;\@@amsalign$\displaystyle c_{11}$&amp;$\displaystyle=\overbrace{\begin{pmatrix}1&amp;2%&#10;\end{pmatrix}}^{\text{Row $1$ of $\mathbf{B}$}}\cdot\underbrace{\begin{pmatrix%&#10;}1\\&#10;0\end{pmatrix}}_{\mathclap{\text{Column $1$ of $\mathbf{A}$}}}=1$&#10;Similarly,&#10;\@@amsalign$\displaystyle c_{32}$&amp;$\displaystyle=\begin{pmatrix}-1&amp;12\end{%&#10;pmatrix}\cdot\begin{pmatrix}2\\&#10;1\end{pmatrix}=10$&#10;So&#10;\@@amsalign$\displaystyle\mathbf{C}=\begin{bmatrix}1&amp;c_{12}\\&#10;c_{21}&amp;c_{22}\\&#10;c_{31}&amp;10\end{bmatrix}_{3\times 2}$&#10;\par&#10;}&#10;\enumerate@item{&#10;Next, we will use the second method. This says that rows of $\mathbf{C}$ are %&#10;linear combinations of rows of $\mathbf{A}$.&#10;\@@amsalign$\displaystyle\text{Row 1}$&amp;$\displaystyle=1\begin{bmatrix}1&amp;2\end{%&#10;bmatrix}+2\begin{bmatrix}0&amp;1\end{bmatrix}$&#10;The coefficients $1$ and $2$ in front of the rows of $\mathbf{A}$ are taken %&#10;from the first row of $\mathbf{B}$.&#10;\@@amsalign$\displaystyle\mathbf{C}=\begin{bmatrix}1&amp;4\\&#10;c_{21}&amp;c_{22}\\&#10;c_{31}&amp;10\end{bmatrix}_{3\times 2}$&#10;}&#10;\enumerate@item{&#10;The next method states that columns of $\mathbf{C}$ are linear combinations of%&#10; columns of $\mathbf{B}$.&#10;\@@amsalign$\displaystyle\text{Column 2}$&amp;$\displaystyle=2\begin{bmatrix}1\\&#10;0\\&#10;-1\end{bmatrix}+1\begin{bmatrix}2\\&#10;0\\&#10;12\end{bmatrix}$\\&#10;$$&amp;$\displaystyle=\begin{bmatrix}4\\&#10;0\\&#10;10\end{bmatrix}$&#10;This allows us to fill in another entry of $\mathbf{C}$:&#10;\@@amsalign$\displaystyle\mathbf{C}=\begin{bmatrix}1&amp;4\\&#10;c_{21}&amp;0\\&#10;c_{31}&amp;10\end{bmatrix}_{3\times 2}$&#10;}&#10;\end{enumerate}&#10;\par&#10;\end{document}" display="block">
  <mrow>
    <merror class="ltx_ERROR undefined undefined">
      <mtext>\tikzstyle</mtext>
    </merror>
    <mi>b</mi>
    <mi>l</mi>
    <mi>k</mi>
    <mo>=</mo>
    <mrow>
      <mo stretchy="false">[</mo>
      <mi>c</mi>
      <mi>i</mi>
      <mi>r</mi>
      <mi>c</mi>
      <mi>l</mi>
      <mi>e</mi>
      <mo>,</mo>
      <mi>i</mi>
      <mi>n</mi>
      <mi>n</mi>
      <mi>e</mi>
      <mi>r</mi>
      <mi>s</mi>
      <mi>e</mi>
      <mi>p</mi>
      <mo>=</mo>
      <mn>0</mn>
      <mi>p</mi>
      <mi>t</mi>
      <mo>,</mo>
      <mi>m</mi>
      <mi>i</mi>
      <mi>n</mi>
      <mi>i</mi>
      <mi>m</mi>
      <mi>u</mi>
      <mi>m</mi>
      <mi>s</mi>
      <mi>i</mi>
      <mi>z</mi>
      <mi>e</mi>
      <mo>=</mo>
      <mn>4</mn>
      <mi>p</mi>
      <mi>t</mi>
      <mo>,</mo>
      <mi>d</mi>
      <mi>r</mi>
      <mi>a</mi>
      <mi>w</mi>
      <mo>,</mo>
      <mi>f</mi>
      <mi>i</mi>
      <mi>l</mi>
      <mi>l</mi>
      <mo>=</mo>
      <mi>b</mi>
      <mi>l</mi>
      <mi>a</mi>
      <mi>c</mi>
      <mi>k</mi>
      <mo>,</mo>
      <mi>l</mi>
      <mi>i</mi>
      <mi>n</mi>
      <mi>e</mi>
      <mi>w</mi>
      <mi>i</mi>
      <mi>d</mi>
      <mi>t</mi>
      <mi>h</mi>
      <mo>=</mo>
      <mn>0.8</mn>
      <mi>p</mi>
      <mi>t</mi>
      <mo stretchy="false">]</mo>
    </mrow>
    <merror class="ltx_ERROR undefined undefined">
      <mtext>\tikzstyle</mtext>
    </merror>
    <mi>b</mi>
    <mi>l</mi>
    <mi>a</mi>
    <mi>n</mi>
    <mi>k</mi>
    <mi>n</mi>
    <mi>o</mi>
    <mi>d</mi>
    <mi>e</mi>
    <mo>=</mo>
    <mrow>
      <mo stretchy="false">[</mo>
      <mi>c</mi>
      <mi>i</mi>
      <mi>r</mi>
      <mi>c</mi>
      <mi>l</mi>
      <mi>e</mi>
      <mo>,</mo>
      <mi>i</mi>
      <mi>n</mi>
      <mi>n</mi>
      <mi>e</mi>
      <mi>r</mi>
      <mi>s</mi>
      <mi>e</mi>
      <mi>p</mi>
      <mo>=</mo>
      <mn>3</mn>
      <mi>p</mi>
      <mi>t</mi>
      <mo>,</mo>
      <mi>m</mi>
      <mi>i</mi>
      <mi>n</mi>
      <mi>i</mi>
      <mi>m</mi>
      <mi>u</mi>
      <mi>m</mi>
      <mi>s</mi>
      <mi>i</mi>
      <mi>z</mi>
      <mi>e</mi>
      <mo>=</mo>
      <mn>8</mn>
      <mi>p</mi>
      <mi>t</mi>
      <mo>,</mo>
      <mi>d</mi>
      <mi>r</mi>
      <mi>a</mi>
      <mi>w</mi>
      <mo>,</mo>
      <mi>l</mi>
      <mi>i</mi>
      <mi>n</mi>
      <mi>e</mi>
      <mi>w</mi>
      <mi>i</mi>
      <mi>d</mi>
      <mi>t</mi>
      <mi>h</mi>
      <mo>=</mo>
      <mn>0.8</mn>
      <mi>p</mi>
      <mi>t</mi>
      <mo stretchy="false">]</mo>
    </mrow>
    <merror class="ltx_ERROR undefined undefined">
      <mtext>\geometry</mtext>
    </merror>
    <mi>l</mi>
    <mi>e</mi>
    <mi>t</mi>
    <mi>t</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mi>p</mi>
    <mi>a</mi>
    <mi>p</mi>
    <mi>e</mi>
    <mi>r</mi>
    <mo>,</mo>
    <mi>t</mi>
    <mi>e</mi>
    <mi>x</mi>
    <mi>t</mi>
    <mi>w</mi>
    <mi>i</mi>
    <mi>d</mi>
    <mi>t</mi>
    <mi>h</mi>
    <mo>=</mo>
    <mn>17</mn>
    <mi>c</mi>
    <mi>m</mi>
    <mo>,</mo>
    <mi>t</mi>
    <mi>e</mi>
    <mi>x</mi>
    <mi>t</mi>
    <mi>h</mi>
    <mi>e</mi>
    <mi>i</mi>
    <mi>g</mi>
    <mi>h</mi>
    <mi>t</mi>
    <mo>=</mo>
    <mn>22</mn>
    <mi>c</mi>
    <mi>m</mi>
    <merror class="ltx_ERROR undefined undefined">
      <mtext>\usetikzlibrary</mtext>
    </merror>
    <mi>a</mi>
    <mi>r</mi>
    <mi>r</mi>
    <mi>o</mi>
    <mi>w</mi>
    <mi>s</mi>
    <merror class="ltx_ERROR undefined undefined">
      <mtext>\usetikzlibrary</mtext>
    </merror>
    <mi>p</mi>
    <mi>l</mi>
    <mi>o</mi>
    <mi>t</mi>
    <mi>m</mi>
    <mi>a</mi>
    <mi>r</mi>
    <mi>k</mi>
    <mi>s</mi>
    <mtext xml:id="Sx1">Recall1.A set of vectors {v→1,v→2,…,v→k} in \bbRn is linearly independent if the following homogenous equation has only the zero (trivial) solution:c1⁢v→1+c2⁢v→2+…+ck⁢v→k=0c1⁢v→1+c2⁢v→2+…+ck⁢v→k=0Note that (Recall) always has a solution, namely c1=c2=…=ck=0. Our interest is whether this is the only solution, or if there are others.It is a common mistake when we first learn this to think that something like “since we can form a linear combination with c1,c2,…,ck=0, thus the set is dependent.”. This is not the case; it must be a solution with at least one coefficient non-zero.2.If the number of vectors in S is greater than the dimension of the space, then S is dependent.Suppose {v→1,v→2,…,v→k} is a dependent set. Then there is at least one ci≠0. Without loss of generality, say c1≠0. Thenc1⁢v→1=-c2⁢v→2-…-ck⁢v→kc1⁢v→1=-c2⁢v→2-…-ck⁢v→kv→1=-c2c1⁢v→2-…-ckc1⁢v→kv→1=-c2c1⁢v→2-…-ckc1⁢v→kThe righthand side of this equation should remind us of the span. In this case, of Span⁢{v→2,…,v→k}. That is, v→1 lies in the span of the other v→i’s.Linear IndependenceQuestion:Consider the set of vectors S={0→,v→2,…,v→k}. Is S independent or dependent? To answer this, we must ask whether the following homogeneous equation has a non-zero solution:c1⁢0→+c2⁢v→2+…+ck⁢v→k=0→c1⁢0→+c2⁢v→2+…+ck⁢v→k=0→Consider for instance the solution c1=3, c2,c3,…,ck=0. This is a non-zero or non-trivial solution, hence S must be dependent.Question:Let S={v→1,v→2,v→3}.
Suppose none of the vectors in S are zero vectors, and each is perpendicular to one another. That is,v→i≠0→v→i≠0→v→i⟂v→j for all i≠jv→i⟂v→j for all i≠jIs S independent or dependent? Before we answer this question, we should observe some noteworthy aspects of this question and how it is posed. If we can find some useful relationships between orthogonality and linear dependence, we will perhaps uncover illuminating geometric relationships.To answer the question at hand, we can start with the equation we already know: the linear combination of vectors that equals the zero vector:c1⁢v→1+c2⁢v→2+c3⁢v→3=0→c1⁢v→1+c2⁢v→2+c3⁢v→3=0→it is initially unclear how the orthogonality will come into play, but consider taking the dot product of both sides of the equation with v→1:(c1⁢v→1+c2⁢v→2+c3⁢v→3)⋅v→1=0→⋅v→1(c1⁢v→1+c2⁢v→2+c3⁢v→3)⋅v→1=0→⋅v→1c1⁢(v→1⋅v→1)+c2⁢(v→2⋅v→1)+c3⁢(v→3⋅v→1)=0c1⁢(v→1⋅v→1)+c2⁢(v→2⋅v→1)+c3⁢(v→3⋅v→1)=0Distributive property of dot productDistributive property of dot productc1⁢||v→1||2+c2⁢(0)+c3⁢(0)=0c1⁢||v→1||2+c2⁢(0)+c3⁢(0)=0The vectors are orthogonal to each otherThe vectors are orthogonal to each otherc1⁢||v→1||2=0c1⁢||v→1||2=0Since v→1≠0→, we know that ||v→1||2≠0. Thus from the above, c1=0.Likewise, we find that c2=c3=0 by taking the dot product with v→2 and v→3.Therefore, the only solution is the zero solution. Thus S must be independent.Note: In an n-dimensional space we cannot have more than n (non-zero) orthogonal vectors.MatricesWe have already seen some examples of matrices as means of storing systems of linear equations. They are simply arrays of numbers laid out in a way in which each entry has a convenient address.𝐀=[a1,1a1,2a1,3a2,1a2,2a2,3]  𝐀2×3𝐀=[a1,1a1,2a1,3a2,1a2,2a2,3]  𝐀2×3The i-jth entry is the entry found in row i and column j. We always give the address of the entry row first and column secondEvery matrix is described by its entries, and we sometimes write it like below:𝐀=(ai⁢j)  ai⁢j∈\bbR,\bbC𝐀=(ai⁢j)  ai⁢j∈\bbR,\bbCFor our purposes, the entries will almost always be from \bbR and \bbC, but keep in mind that the entries could be any object.It is also important to note the size of a matrix, and we often do this by saying that 𝐀 is an n×m matrix, or writing 𝐀n×m.Algebra of MatricesSuppose 𝐀m×n and 𝐁m×n are matrices of the same size. We define several operations on matrices as follows:OperationDefinition by EntryResultant SizeMatrix additionA + B=( aij + bij )m ×nMatrix subtractionA - B=( aij - bij )m ×nScalar multiplicationc A=( c   aij )   c is a scalarm ×nExample.𝐀=[[r⁢r⁢r]⁢12301-5]𝐀=[[r⁢r⁢r]⁢12301-5]𝐁=[[r⁢r⁢r]⁢56-6003]𝐁=[[r⁢r⁢r]⁢56-6003]𝐂=[[r⁢r⁢r]⁢1230]𝐂=[[r⁢r⁢r]⁢1230]Then 𝐀+5⁢𝐁 is given by𝐀+5⁢𝐁=[[r⁢r⁢r]⁢12301-5]+[[r⁢r⁢r]⁢2530-300015]=[[r⁢r⁢r]⁢2632-270110]𝐀+5⁢𝐁=[[r⁢r⁢r]⁢12301-5]+[[r⁢r⁢r]⁢2530-300015]=[[r⁢r⁢r]⁢2632-270110]Some may wonder what the result of an addition such as 𝐀+𝐂 would be. Since the dimensions of these matrices do not match, such an addition is not defined. It is common to wonder whether we could just add a column of zeros to the matrix 𝐂 in order to make the operation defined. The response to this is that of course we could do that, but it would completely change the matrix 𝐂, so we do not allow this type of operation.These are the simplest types of operations we can define on matrices. Two elementary operations remain: multiplication and division. We might also wonder about operations such as logarithm and exponentiation. We will get to those types of operations later.Matrix MultiplicationMatrix multiplication at first seems very strange. If we consider trying to define a multiplication on two matrices, we might conclude from seeing addition and subtraction that to multiply matrices they should be the same size. In fact this is not the case.Before we discuss the full definition of matrix multiplication, consider the dot product:[123]⋅[abc]=a+2⁢b+3⁢c[123]⋅[abc]=a+2⁢b+3⁢cIf the vectors had an unequal number of components then the dot product would not be defined. If we consider the scalar a+2⁢b+3⁢c to be the sole entry in a matrix of size 1×1, then this tells us one possible set of sizes for which matrix multiplication is defined:[123]⏟1×3⁢[abc]⏟3×1=[a+2⁢b+3⁢c]⏟1×1[123]⏟1×3⁢[abc]⏟3×1=[a+2⁢b+3⁢c]⏟1×1The dimensions of matrices that can be multiplied can be summarized as𝐀m×n⁢𝐁n×p=𝐂m×p𝐀m×n⁢𝐁n×p=𝐂m×pExample.𝐀2×3=[123-140]𝐀2×3=[123-140]𝐁3×1=[pqr]𝐁3×1=[pqr]Consider the product𝐀𝐁=[123-140]⁢[pqr]𝐀𝐁=[123-140]⁢[pqr]We can evaluate this by ignoring one row at a time of 𝐀:𝐀𝐁=[123]⁢[pqr]=[p+2⁢q+3⁢r]𝐀𝐁=[-140]⁢[pqr]=[-p+4⁢q+0⁢r]}𝐀𝐁=[123]⁢[pqr]=[p+2⁢q+3⁢r]𝐀𝐁=[-140]⁢[pqr]=[-p+4⁢q+0⁢r]}⟶⟶𝐀𝐁=[123-140]⁢[pqr]=[p+2⁢q+3⁢r-p+4⁢q+0⁢r]2×1𝐀𝐁=[123-140]⁢[pqr]=[p+2⁢q+3⁢r-p+4⁢q+0⁢r]2×1It may be startling to observe the outcome of trying to multiply 𝐁 by 𝐀:𝐁3×1⁢𝐀2×3=Not defined𝐁3×1⁢𝐀2×3=Not definedBecause the dimensions of the two matrices do not correctly line up in this order, they cannot be multiplied in this way. The technical term for this is that, in general, matrix multiplication is non-commutative. That is, 𝐀𝐁≠𝐁𝐀. In fact, both need not be defined at all, depending on their sizes.Another Perspective on Matrix MultiplicationConsider again the matrix multiplication from the previous example. We can view this multiplication in a number of ways:𝐀𝐁=[123-140]⁢[pqr]𝐀𝐁=[123-140]⁢[pqr]=[p+2⁢q+3⁢r-p+4⁢q+0⁢r]=[p+2⁢q+3⁢r-p+4⁢q+0⁢r]⟸Each row is a linear combination of rows of 𝐁⟸Each row is a linear combination of rows of 𝐁=p⁢[1-1]+q⁢[24]+r⁢[30]=p⁢[1-1]+q⁢[24]+r⁢[30]⟸Linear combination of the columns of 𝐀⟸Linear combination of the columns of 𝐀The three ways of viewing matrix multiplication are1.ci⁢j=(←row i of 𝐀→)⁢(↑col. jof 𝐁↓)ci⁢j=(←row i of 𝐀→)⁢(↑col. jof 𝐁↓)2.ith row of 𝐂 is a linear combination of rows of 𝐁 with coefficients from the ith row of 𝐀.3.jth column of 𝐂 is a linear combination of columns of 𝐀 with coefficients from the jth column of 𝐁.Example.We will try multiplication with each of the three ways of viewing matrix multiplication.𝐀=[1201]𝐀=[1201]𝐁=[1200-112]𝐁=[1200-112]Note that 𝐀𝐁 is not defined, but 𝐁𝐀 is defined. Let 𝐂=𝐁𝐀, the matrix whose entries we will try to find.1.First method:𝐂=[c11c12c21c22c31c32]3×2𝐂=[c11c12c21c22c31c32]3×2c11=(12)⏞Row 1 of 𝐁⋅(10)⏟\mathclap⁢Column 1 of 𝐀=1c11=(12)⏞Row 1 of 𝐁⋅(10)⏟\mathclap⁢Column 1 of 𝐀=1Similarly,c32=(-112)⋅(21)=10c32=(-112)⋅(21)=10So𝐂=[1c12c21c22c3110]3×2𝐂=[1c12c21c22c3110]3×22.Next, we will use the second method. This says that rows of 𝐂 are linear combinations of rows of 𝐀.Row 1=1⁢[12]+2⁢[01]Row 1=1⁢[12]+2⁢[01]The coefficients 1 and 2 in front of the rows of 𝐀 are taken from the first row of 𝐁.𝐂=[14c21c22c3110]3×2𝐂=[14c21c22c3110]3×23.The next method states that columns of 𝐂 are linear combinations of columns of 𝐁.Column 2=2⁢[10-1]+1⁢[2012]Column 2=2⁢[10-1]+1⁢[2012]=[4010]=[4010]This allows us to fill in another entry of 𝐂:𝐂=[14c210c3110]3×2𝐂=[14c210c3110]3×2</mtext>
  </mrow>
</math>
